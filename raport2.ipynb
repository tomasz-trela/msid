{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raport z implementacji modeli uczenia maszynowego\n",
    "\n",
    "## 1. Wstęp\n",
    "**Cel projektu**:  \n",
    "Klasyfikacja stanów otyłości (7 klas) na podstawie nawyków żywieniowych i parametrów fizycznych.  \n",
    "**Zbiór danych**:  \n",
    "obesity_data.csv (2111 próbek, 17 cech)  \n",
    "\n",
    "## 2. Szczegółowa analiza preprocessingu\n",
    "\n",
    "### 2.1 Struktura transformacji\n",
    "Pipeline przetwarzania wykorzystuje `ColumnTransformer` do równoległego przetwarzania różnych typów cech:\n",
    "\n",
    "\n",
    "### 2.2 Rodzaje transformacji\n",
    "1. **Cechy binarne** (np. płeć):\n",
    "   - Kodowanie 0/1 przez `OrdinalEncoder`\n",
    "   - Przykład: \"Male\" → 0, \"Female\" → 1\n",
    "\n",
    "3. **Cechy kategoryczne** (sposób przemieszczania się):\n",
    "- Pełne one-hot encoding przez `OneHotEncoder`\n",
    "\n",
    "### 2.3 Skalowanie\n",
    "- `RobustScaler` stosowany globalnie po transformacji kategorycznej\n",
    "- Odporny na outliery poprzez użycie mediany\n",
    "\n",
    "### 2.4 Wyniki modeli scikit-learn\n",
    "| Model                  | Dokładność |\n",
    "|------------------------|------------|\n",
    "| DecisionTree           | 60.9%      |\n",
    "| LogisticRegression     | 53.9%      |\n",
    "| SVC                    | 62.4%      |\n",
    "\n",
    "## 3. Implementacje w numpy \n",
    "### 3.1 Regresja zamkniętą formułą\n",
    "\n",
    "**Ograniczenia**:  \n",
    "- Brak stabilności numerycznej dla `X.T @ X` przy dużych wymiarach\n",
    "- Podatność na outliery\n",
    "- Nieefektywne n^3\n",
    "- Nie radzi sobie dobrze z danymi, które mają nieliniową strukturę\n",
    "\n",
    "### 3.2 Regresja logistyczna z GD\n",
    "\n",
    "**Ograniczenia**:  \n",
    "- Kluczowe hiperparametry, jak learning rate czy liczba epok, trzeba dobrać ręcznie lub metodami optymalizacji.\n",
    "- Gradient descent minimalizuje błąd ogólny, więc przy dużej dysproporcji klas może ignorować mniejszościową klasę.\n",
    "\n",
    "### 3.3 Porównanie wydajności\n",
    "| Metoda                 | Dokładność |\n",
    "|------------------------|------------|\n",
    "| Własna regresja        | 14.4%      |\n",
    "| Scikit-learn           | 53.9%      |\n",
    "\n",
    "**Analiza**:  \n",
    "Różnica wynika z braku optymalizacji w implementacji własnej (brak regularyzacji, prosty GD)\n",
    "\n",
    "## 4. Implementacja w PyTorch \n",
    "\n",
    "### 4.1 Wyniki GPU vs CPU\n",
    "| Metryka                | CPU      | GPU      |\n",
    "|------------------------|----------|----------|\n",
    "| Czas                   | 9.73s    | 13.1s    |\n",
    "\n",
    "**Analiza**:\n",
    "Powody dlaczego czas trenowania na cpu jest mniejszy niż na gpu\n",
    "- Mały rozmiar danych – GPU zyskuje przewagę przy dużych macierzach, dla małych zbiorów dane mogą się szybciej przetwarzać na CPU ze względu na mniejsze koszty narzutu.\n",
    "- Overhead związany z inicjalizacją GPU – uruchomienie kerneli GPU i zarządzanie nimi może zająć więcej czasu niż bezpośrednie wykonanie kodu na CPU.\n",
    "- Niewielka liczba operacji matematycznych – regresja logistyczna to stosunkowo prosty model, który nie wykorzystuje w pełni równoległych możliwości GPU.\n",
    "- Koszt przenoszenia danych do/z GPU – kopiowanie danych między pamięcią RAM (CPU) a pamięcią GPU może zająć więcej czasu niż samo obliczenie na CPU.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
